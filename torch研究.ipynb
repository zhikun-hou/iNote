{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Linear(2,1)\n",
    "        self.reset()\n",
    "    def forward(self,X):\n",
    "        return self.mlp(X)\n",
    "    def reset(self):\n",
    "        # 对weight全1初始化、bias全0初始化，便于之后的研究\n",
    "        self.mlp.weight.data.fill_(1)\n",
    "        self.mlp.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "- 关闭Dropout层\n",
    "- BatchNorm层停止更新均值和方差\n",
    "- 仍然会计算梯度，只是不进行反向传播\n",
    "\n",
    "model.train()\n",
    "- 开启Dropout层\n",
    "- BatchNorm层保持更新均值和方差\n",
    "\n",
    "with torch.no_grad()\n",
    "- 不开启梯度的反向传播，节省计算资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "由于weight全1bias全0，输出的Z为：tensor([[2.]])\n",
      "\n",
      "前向传播时，梯度为：None\n",
      "\n",
      "反向传播时，梯度为：tensor([[0., 4.]])\n",
      "\n",
      "在with no_grad()中使用loss.backward()会导致报错\n",
      "\n",
      "梯度已清空：None\n",
      "参数更新为：tensor([[1.0000, 0.5000]])\n",
      "model.zero_grad()和optimizer.step()都会清空参数的梯度，区别在于一个不训练参数，一个训练\n",
      "\n",
      "当前梯度：tensor([[0., 4.]])\n",
      "可见，eval()模式下梯度仍会更新\n",
      "如果loss更新后没有optimizer.step()，那么新梯度会叠加在旧梯度上：tensor([[0., 8.]])\n",
      "\n",
      "更新前：tensor([[1., 1.]])\n",
      "更新后：tensor([[1.0000, 0.5174]])\n",
      "eval()模式下，仍然可以手动进行optimizer.step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = TestModel()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.5)\n",
    "\n",
    "X = torch.tensor([[0,2]]).float()\n",
    "Y = torch.tensor([[1]]).float()\n",
    "\n",
    "Z = model(X)\n",
    "print(\"由于weight全1bias全0，输出的Z为：{}\\n\".format(Z.detach()))\n",
    "\n",
    "loss = F.mse_loss(Z,Y)\n",
    "print(\"前向传播时，梯度为：{}\\n\".format(model.mlp.weight.grad))\n",
    "\n",
    "loss.backward()\n",
    "print(\"反向传播时，梯度为：{}\\n\".format(model.mlp.weight.grad))\n",
    "\n",
    "# 测试no_grad()\n",
    "print(\"在with no_grad()中使用loss.backward()会导致报错\\n\")\n",
    "\n",
    "# # 取消注释以查看报错信息\n",
    "# with torch.no_grad():\n",
    "#     Z = model(X)\n",
    "#     loss = F.mse_loss(Z,Y)\n",
    "#     loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "model.zero_grad()\n",
    "print(\"梯度已清空：{}\".format(model.mlp.weight.grad))\n",
    "print(\"参数更新为：{}\".format(model.mlp.weight.data))\n",
    "print(\"model.zero_grad()和optimizer.step()都会清空参数的梯度，区别在于一个不训练参数，一个训练\\n\")\n",
    "\n",
    "# 把模型参数恢复为初始状态\n",
    "model.reset()\n",
    "\n",
    "# 测试eval\n",
    "model.eval()\n",
    "Z = model(X)\n",
    "loss = F.mse_loss(Z,Y)\n",
    "loss.backward()\n",
    "print(\"当前梯度：{}\".format(model.mlp.weight.grad))\n",
    "print(\"可见，eval()模式下梯度仍会更新\")\n",
    "\n",
    "Z = model(X)\n",
    "loss = F.mse_loss(Z,Y)\n",
    "loss.backward()\n",
    "print(\"如果loss更新后没有optimizer.step()，那么新梯度会叠加在旧梯度上：{}\\n\".format(model.mlp.weight.grad))\n",
    "\n",
    "print(\"更新前：{}\".format(model.mlp.weight.data))\n",
    "optimizer.step()\n",
    "print(\"更新后：{}\".format(model.mlp.weight.data))\n",
    "print(\"eval()模式下，仍然可以手动进行optimizer.step()\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "装饰器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.no_grad()与optimizer.no_grad()在单台机器单张显卡时没有区别\n",
    "这里无法演示，跳过"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
